import { type NextRequest, NextResponse } from "next/server";
import { auth } from "@clerk/nextjs/server";
import * as fal from "@fal-ai/serverless-client";
import { put } from "@vercel/blob";
import { db } from "@/lib/db";
import { participants } from "@/lib/schema";
import { eq } from "drizzle-orm";
import sharp from "sharp";

fal.config({
  credentials: process.env.FAL_API_KEY,
});

function base64ToFile(base64String: string, filename = "upload.jpg"): File {
  const matches = base64String.match(/^data:([A-Za-z-+/]+);base64,(.+)$/);

  if (!matches || matches.length !== 3) {
    throw new Error("Invalid base64 string");
  }

  const mimeType = matches[1];
  const base64Data = matches[2];

  const binaryString = atob(base64Data);
  const bytes = new Uint8Array(binaryString.length);

  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }

  return new File([bytes], filename, { type: mimeType });
}

export async function POST(request: NextRequest) {
  try {
    const { userId } = await auth();

    if (!userId) {
      return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
    }

    const { profilePhotoUrl } = await request.json();

    if (!profilePhotoUrl) {
      return NextResponse.json(
        { error: "Profile photo URL required" },
        { status: 400 }
      );
    }

    if (!db) {
      return NextResponse.json(
        { error: "Database not configured" },
        { status: 500 }
      );
    }

    const participant = await db.query.participants.findFirst({
      where: eq(participants.clerkUserId, userId),
    });

    if (!participant) {
      return NextResponse.json(
        { error: "Participant not found" },
        { status: 404 }
      );
    }

    console.log("[ai-photo] Starting pixel art generation with qwen-image-edit for participant", participant.id);

    // Fetch the user's profile photo
    console.log("[ai-photo] Fetching user profile photo:", profilePhotoUrl);
    const photoResponse = await fetch(profilePhotoUrl);
    const photoBuffer = Buffer.from(await photoResponse.arrayBuffer());
    const photoBase64 = `data:image/jpeg;base64,${photoBuffer.toString("base64")}`;

    console.log("[ai-photo] Converting base64 to File and uploading to fal.storage");
    const imageFile = base64ToFile(photoBase64, "profile-photo.jpg");
    const uploadedImageUrl = await fal.storage.upload(imageFile);
    console.log("[ai-photo] Image uploaded to fal.storage:", uploadedImageUrl);

    const prompt =
      "8-bit pixel art portrait, chest-up view. Simple solid background for easy cutout. Flat grayscale shading with four tones. Printed, cartoonish, and cute. Preserve facial structure. The character should fit entirely within the frame, without labels or text.";

    console.log("[ai-photo] Calling qwen-image-edit with uploaded image URL");
    const result = (await fal.subscribe("fal-ai/qwen-image-edit", {
      input: {
        prompt,
        image_url: uploadedImageUrl,
      },
    })) as {
      data?: { images?: Array<{ url: string }>; image?: { url: string } };
      images?: Array<{ url: string }>;
      image?: { url: string };
    };

    console.log("[ai-photo] FAL result received");

    let imageUrl: string | undefined;

    if (result.data?.images && Array.isArray(result.data.images) && result.data.images.length > 0) {
      imageUrl = result.data.images[0].url;
      console.log("[ai-photo] Found image in result.data.images");
    } else if (result.images && Array.isArray(result.images) && result.images.length > 0) {
      imageUrl = result.images[0].url;
      console.log("[ai-photo] Found image in result.images");
    } else if (result.data?.image?.url) {
      imageUrl = result.data.image.url;
      console.log("[ai-photo] Found image in result.data.image");
    } else if (result.image?.url) {
      imageUrl = result.image.url;
      console.log("[ai-photo] Found image in result.image");
    }

    if (!imageUrl) {
      console.error("[ai-photo] Could not find image URL in result. Available keys:", Object.keys(result as object));
      if (result.data) {
        console.error("[ai-photo] result.data keys:", Object.keys(result.data as object));
      }
      return NextResponse.json(
        { error: "No images generated by FAL API" },
        { status: 500 },
      );
    }

    console.log("[ai-photo] Successfully generated pixel art image:", imageUrl);

    console.log("[ai-photo] Removing background from pixel art");
    
    interface QueueUpdate {
      status: string;
      logs?: Array<{ message: string }>;
    }
    
    const bgRemovalResult = (await fal.subscribe("fal-ai/birefnet/v2", {
      input: {
        image_url: imageUrl,
      },
      logs: true,
      onQueueUpdate: (update: QueueUpdate) => {
        if (update.status === "IN_PROGRESS" && update.logs) {
          update.logs.map((log) => log.message).forEach(console.log);
        }
      },
    })) as { data?: { image?: { url: string } }; image?: { url: string } };

    let transparentImageUrl: string | undefined;

    if (bgRemovalResult.data?.image?.url) {
      transparentImageUrl = bgRemovalResult.data.image.url;
      console.log("[ai-photo] Background removed successfully:", transparentImageUrl);
    } else if (bgRemovalResult.image?.url) {
      transparentImageUrl = bgRemovalResult.image.url;
      console.log("[ai-photo] Background removed successfully:", transparentImageUrl);
    } else {
      console.warn("[ai-photo] Could not remove background, using original image");
      transparentImageUrl = imageUrl;
    }

    const finalImageUrl = transparentImageUrl || imageUrl;
    console.log("[ai-photo] Final image URL:", finalImageUrl);

    // Download and upload to Vercel Blob
    const finalImageResponse = await fetch(finalImageUrl);
    const finalImageBuffer = Buffer.from(await finalImageResponse.arrayBuffer());

    const processedPixelArt = await sharp(finalImageBuffer)
      .resize(700, 700, { fit: "cover" })
      .png()
      .toBuffer();

    const timestamp = Date.now();
    const blobResult = await put(
      `ai-profile-photos/${participant.id}-${timestamp}.png`,
      processedPixelArt,
      { access: "public", contentType: "image/png" }
    );

    console.log("[ai-photo] Uploaded AI photo to Vercel Blob:", blobResult.url);

    await db
      .update(participants)
      .set({
        profilePhotoAiUrl: blobResult.url,
        updatedAt: new Date(),
      })
      .where(eq(participants.id, participant.id));

    console.log("[ai-photo] AI profile photo generated successfully");

    return NextResponse.json({
      aiPhotoUrl: blobResult.url,
    });
  } catch (error) {
    console.error("[ai-photo] Pixel art generation failed");
    console.error("[ai-photo] Error type:", typeof error);
    console.error("[ai-photo] Error constructor:", error?.constructor?.name);

    const errorDetails = JSON.stringify(error, Object.getOwnPropertyNames(error), 2);
    console.error("[ai-photo] Full error object:", errorDetails);

    if (error && typeof error === "object") {
      const err = error as Record<string, unknown>;
      console.error("[ai-photo] Error.name:", err.name);
      console.error("[ai-photo] Error.message:", err.message);
      console.error("[ai-photo] Error.status:", err.status);
      console.error("[ai-photo] Error.body:", err.body);
      console.error("[ai-photo] Error.stack:", err.stack);
    }

    const errorMessage = error instanceof Error ? error.message : String(error);
    return NextResponse.json(
      {
        error: "Failed to generate AI profile photo",
        details: errorMessage,
      },
      { status: 500 }
    );
  }
}

